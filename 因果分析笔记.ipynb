{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac219826",
   "metadata": {},
   "source": [
    "# 金融模型因果分析研究思路\n",
    "\n",
    "--------作者：王晟（sw@fip.ai）--------------\n",
    "\n",
    "## 概念\n",
    "\n",
    "- 因果推断： 根据一个结果发生的条件对因果关系得出结论的过程。\n",
    "- 研究目标：研究因果关系最大的一个目标，就是找出事物之间真正的因果关系，去掉那些混杂的伪因果关系。\n",
    "\n",
    "因果关系的三个层次：\n",
    "- 关联（Association）：通过观察到的数据找出变量之间的关系。但不能挖掘出事件A导致事件B的发生。\n",
    "- 干预（Intervention）：当改变事件A时，事件B也随之改变。\n",
    "- 反事实推理（Conterfactuals）：也即“执果索因”，想让事件B也发生某种变化时，能否通过改变事件A来实现。\n",
    "\n",
    "## 研究方法\n",
    "\n",
    "- 实验性研究：随机对照实验，代价昂贵且费时费力。\n",
    "- 观测性研究：从已有的观测数据中进行因果关系的研究，简单高效易于理解。\n",
    "    - 因果图模型\n",
    "    - 潜在结果框架\n",
    "\n",
    "## 模型与框架\n",
    "\n",
    "- 因果图模型：因果图是基于DAG(有向无环图)构建的，它是一种概率因果模型，被用来编码有关数据生成过程的假设。\n",
    "    - 结构化因果图模型（SCM）：集合U={X,W}为外生变量集合，集合V={Z,Y}为内生变量集合，集合F={f,g}为函数集合\n",
    "- 潜在结果模型（Rubin Causal Model）：比较同一个研究对象(Unit)在接受干预(Treatment)和不接受干预(对照/控制组)时结果差异，认为这一结果差异就是接受干预相对于不接受干预的效果。\n",
    "    - 对于接受干预的研究对象而言，不接受干预时的状态是一种“反事实”状态；对于不接受干预的研究对象而言，接受干预时的状态也是一种“反事实”状态；所以该模型又被某些研究者称之为反事实框架(Counter factual Framework)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7f728",
   "metadata": {},
   "source": [
    "### 反事实框架\n",
    "\n",
    "- 基本概念\n",
    "    - Unit（单元）：原子研究对象\n",
    "    - Treatment（干预/治疗）：施加给一个原子对象unit的行为\n",
    "    - Outcome（结果）：在对unit进行Treatment或者仅仅作为对照之后unit随后产生的反应/结果\n",
    "    - Treatment Effect（因果效应）：对unit进行不同Treatment之后unit产生的Outcome的变化，这种效应可以定义在整体层面、treatment组层面、子组层面和个体层面\n",
    "\n",
    "- 基本假设\n",
    "    - 稳定单位干预值假设(Stable Unit Treatment Value Assumption)\n",
    "        - unit之间都是相互独立的，unit之间不会存在相互作用\n",
    "        - 同一treatment仅能存在一个版本\n",
    "    - 可忽略性假设(Ignorability)\n",
    "        - 给定背景变量X,干预分配W，与潜在的结果无关\n",
    "    - 积极性/正值假设(Positivity)\n",
    "        - 对于X的任何一组值，处理分配不是确定的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75aae99",
   "metadata": {},
   "source": [
    "### Simpson悖论\n",
    "\n",
    "- 基本概念\n",
    "    - 辛普森悖论指的是同一组数据，整体的趋势和分组后的趋势完全不同。也就是说，整体数据和分组数据产生的结论截然相反。\n",
    "\n",
    "- 为什么一般的研究方法不适用\n",
    "    - 核心问题：如何估计特定人群的平均潜在治疗/控制结果？\n",
    "    - 想当然的解决方案： 计算平均治疗和对照结果之间的差异，即ATE\n",
    "    - 存在的问题：由于混杂因素(confounders)的存在，这种解决方案是不合理的\n",
    "    \n",
    "- 混杂因素（Confounders）\n",
    "    - 混杂因素(Confounders)是同时影响干预分配（方案的选择）和最终结果的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ef7bf",
   "metadata": {},
   "source": [
    "### 因果推断方法\n",
    "\n",
    "- Re-weighting(重加权算法)\n",
    "\n",
    "- Stratification(分层算法)\n",
    "\n",
    "- Matching(匹配算法)\n",
    "\n",
    "- Tree-based(基于树的方法)\n",
    "\n",
    "- Representation Learning(表示学习)\n",
    "\n",
    "- Multitask Learning(多任务学习)\n",
    "\n",
    "- Meta-learning(元学习)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550bb1d",
   "metadata": {},
   "source": [
    "## 应用\n",
    "\n",
    "- 三个方向\n",
    "    - 决策评估 —— 这与Treatment效果评估的目标是一致的。\n",
    "    - 反事实估计 —— 反事实学习极大地帮助了与决策相关的领域，因为它可以提供不同决策选择（或策略）的潜在结果。\n",
    "    - 处理选择偏差 —— 在许多实际应用程序中，出现在收集的数据集中的记录并不代表感兴趣的整个群体。如果不恰当地处理选择偏差，将影响训练模型的泛化。\n",
    "    \n",
    "![三个方向](./image.png \"Three directions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fe199",
   "metadata": {},
   "source": [
    "## microsoft EconML框架研究\n",
    "\n",
    "### Overview\n",
    "\n",
    "EconML这个Python工具包旨在测量某些干预变量T对结果变量Y的causal effect，控制一组特征X和W，来衡量causal effect如何随X的变化而变化。\n",
    "\n",
    "异质处理效应 （Heterogenous treatment effects,HTE） 简单理解就是按某些规律进行分组之后的ATE，也就是“条件平均处理效应”(Conditional Average Treatment Effect，CATE) 。**每个子组的平均处理效应被称为“条件平均处理效应”(Conditional Average Treatment Effect，CATE)** ，也就是说，条件平均处理效应以子组内的分类方式为条件。\n",
    "在EconML中，“条件平均处理效应”(Conditional Average Treatment Effect，CATE) 的四种估计方式：\n",
    "\n",
    "- 双机器学习(Double Machine Learning)。DML的几种方法包括：\n",
    "    - econml.dml.DML(, model_y, model_t, model_final) # 基础双重ML的模型\n",
    "    - econml.dml.LinearDML([, model_y, model_t, …]) # 线性估计器\n",
    "    - econml.dml.SparseLinearDML([, model_y, …]) # 稀疏线性估计器\n",
    "    - econml.dml.CausalForestDML([, model_y, …]) # 因果树\n",
    "    - econml.dml.NonParamDML(*, model_y, model_t, …) # 非参数ML估计器， that can have arbitrary final ML models of the CATE.\n",
    "\n",
    "- 双重鲁棒学习(Doubly Robust Learner)。双重鲁棒学习(Doubly Robust Learner)几种方法：\n",
    "    - econml.dr.DRLearner([, model_propensity, …])\n",
    "    - econml.dr.LinearDRLearner([, …])\n",
    "    - econml.dr.SparseLinearDRLearner([, …])\n",
    "    - econml.dr.ForestDRLearner([, …])\n",
    "CATE estimator that uses doubly-robust correction techniques to account for covariate shift (selection bias) between the treatment arms.\n",
    "\n",
    "- 元学习器(Meta Learners)。元学习器(Meta Learners)四种方法：\n",
    "    - econml.metalearners.XLearner(, models[, …])\n",
    "    - econml.metalearners.TLearner(, models[, …])\n",
    "    - econml.metalearners.SLearner(, overall_model)\n",
    "    - econml.metalearners.DomainAdaptationLearner(, …) 元算法，使用领域适应技术来解释\n",
    "\n",
    "- 正交随机树(Orthogonal Random Forest)。正交随机树(Orthogonal Random Forest) 的两种方法：\n",
    "    - econml.orf.DMLOrthoForest([, n_trees, …])\n",
    "    - econml.orf.DROrthoForest([, n_trees, …])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d647",
   "metadata": {},
   "source": [
    "\n",
    "### 使用方法\n",
    "\n",
    "**1. 基本使用步骤**\n",
    "- 目标：用于分析Treatment效应（比如贷款给客户其经营情况变化），最终导致结果发生的概率。\n",
    "- 安装和导入econml。\n",
    "- 准备数据集，确保数据被正确地划分为特征、处理变量和结果变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea54677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "X = data[['feature1', 'feature2', 'feature3']]  # 特征\n",
    "T = data['treatment']  # 处理变量\n",
    "Y = data['outcome']  # 结果变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358681da",
   "metadata": {},
   "source": [
    "- 选择预测模型。根据数据特征，选择一种或多种预测模型，比如DML、DRIV和CausalForest等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f32c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dml import LinearDML\n",
    "dml = LinearDML()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0252b2",
   "metadata": {},
   "source": [
    "- 模型拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml.fit(X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001c5ef",
   "metadata": {},
   "source": [
    "- 效果评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_effect = dml.effect(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5f039",
   "metadata": {},
   "source": [
    "- 结果解释及敏感度分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5249b",
   "metadata": {},
   "source": [
    "- 后续优化及模型诊断"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfc8e5",
   "metadata": {},
   "source": [
    "**2. 常用模型分类**\n",
    "- Double Machine Learning：主要是Linear和Tree的模型系列。DML通过两个阶段的机器学习来减少处理效应估计中的偏差。\n",
    "- Gradient Boosting Modles：主要是XGBoost、LightGBM等，比RandamForest一般性能更好。通过逐步添加树来改进模型的预测精度。但econML并不凸显这几个model。\n",
    "- Causal Forest（因果森林）& Orthogonal Random Forests（正交随机森林）：为因果推断设计的森林系列模型；通过构建多棵树并限制每棵树可以使用的特征子集来减少偏差。\n",
    "- Meta-Learners 元学习器：使用一个“元”模型来学习如何从其他机器学习模型的预测中估计处理效应。元学习器可以基于其他模型的残差来调整和改进因果效应的估计。\n",
    "- Double Robust Learner（双重鲁棒学习器）：能够利用机器学习模型的预测能力，又能够保证因果推断的准确性，可以考虑使用双重稳健学习者。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d3213",
   "metadata": {},
   "source": [
    "**3. 建议步骤**\n",
    "- 数据探索：首先进行数据探索，了解数据的分布、特征之间的关系以及是否存在潜在的混杂因素。\n",
    "- 特征工程：进行特征工程，创建可能有助于模型预测的特征，如交互项、多项式特征等。\n",
    "- 模型选择：\n",
    "    - 从随机森林开始，最熟悉这种模型。\n",
    "    - 尝试梯度提升模型，看看是否能提供更好的性能。\n",
    "    - 如果需要更复杂的模型，可以尝试神经网络。\n",
    "    - 交叉验证：使用交叉验证来评估不同模型的性能。\n",
    "    - 因果推断分析：使用EconML的因果推断功能，如因果森林或双重稳健学习者，进行因果推断分析。\n",
    "- 模型比较：比较不同模型的性能，选择表现最好的模型。\n",
    "- 模型解释性：选择模型后，使用模型解释性工具来理解模型的决策过程。\n",
    "- 敏感性分析：进行敏感性分析，以评估结果对潜在未观察到的混杂因素的稳健性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae3781",
   "metadata": {},
   "source": [
    "**4. 估计方法**\n",
    "- Double Machine Learning (aka RLearner) 双重机器学习\n",
    "\n",
    "使用场景：适用于处理效应估计，当数据集较大且你希望利用机器学习模型的预测能力时。DML通过两个阶段的机器学习模型来减少偏差。\n",
    "\n",
    "- Dynamic Double Machine Learning 动态双重机器学习\n",
    "\n",
    "使用场景：适用于处理具有时间序列数据或面板数据的情况，其中处理效应可能随时间变化。\n",
    "\n",
    "- Causal Forests 因果森林\n",
    "\n",
    "使用场景：适用于处理高维数据或复杂的非线性关系，因果森林是一个基于随机森林的集成方法，可以估计异质性处理效应。\n",
    "\n",
    "- Orthogonal Random Forests 正交随机森林\n",
    "\n",
    "使用场景：类似于因果森林，但更侧重于减少模型估计中的偏差，通过正交化技术来减少混杂变量的影响\n",
    "- Meta-Learners 元学习器\n",
    "\n",
    "使用场景：适用于需要在模型选择阶段进行交叉验证来选择最优模型时，元学习器可以在内部进行模型选择和验证\n",
    "\n",
    "- Doubly Robust Learners 双重稳健学习器\n",
    "\n",
    "使用场景：适用于你拥有一些处理分配的模型信息，但可能不完全准确时。双重稳健方法结合了回归调整和工具变量方法，即使其中一个方法失败，也可以提供一致的估计\n",
    "\n",
    "- Double Machine Learning with Instrumental Variables 带工具变量的双重机器学习\n",
    "\n",
    "使用场景：适用于处理分配受到某种随机化影响，但你担心存在遗漏变量偏差时。这种方法结合了双重机器学习和工具变量方法\n",
    "\n",
    "- Doubly Robust Machine Learning with Instrumental Variables 带工具变量的双重稳健机器学习\n",
    "\n",
    "使用场景：适用于处理分配受到工具变量影响，同时希望通过回归调整来控制混杂变量时\n",
    "\n",
    "- Deep Instrumental Variables 深度工具变量\n",
    "\n",
    "使用场景：适用于当数据具有复杂的非线性结构，且你希望通过深度学习模型来捕捉这些结构时，同时使用工具变量来处理潜在的内生性问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed561b15",
   "metadata": {},
   "source": [
    "### 应用案例\n",
    "\n",
    "**1. 双重机器学习（Double Machine Learning, DML）**\n",
    "\n",
    "双重机器学习是一种在观察到所有潜在混杂因素/控制变量（在收集的数据中同时直接影响处理决策和观察结果的因素）时，估计（异质性）处理效应的方法。但是，这些控制变量对于经典的统计方法来说要么太多（高维）而无法应用，要么它们对处理结果和结果的影响不能通过参数函数（非参数）令人满意地建模。这两个问题都可以通过机器学习技术来解决。\n",
    "\n",
    "该方法首先将问题简化为估计两个预测任务：\n",
    "- 根据控制变量预测结果，\n",
    "- 根据控制变量预测处理；\n",
    "\n",
    "然后，该方法将这两个预测模型结合在最后阶段的估计中，以创建异质性处理效应的模型。该方法允许使用任意的机器学习算法来完成这两个预测任务，同时保持与最终模型相关的许多有利的统计特性（例如，小的均方误差，渐近正态性，置信区间的构建）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install econml\n",
    "\n",
    "'''Linear final stage'''\n",
    "from econml.dml import LinearDML\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.inference import BootstrapInference\n",
    "\n",
    "est = LinearDML(model_y=LassoCV(), model_t=LassoCV())\n",
    "### Estimate with OLS confidence intervals\n",
    "est.fit(Y, T, X=X, W=W) # W -> high-dimensional confounders, X -> features\n",
    "treatment_effects = est.effect(X_test)\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05) # OLS confidence intervals\n",
    "\n",
    "### Estimate with bootstrap confidence intervals\n",
    "est.fit(Y, T, X=X, W=W, inference='bootstrap')  # with default bootstrap parameters\n",
    "est.fit(Y, T, X=X, W=W, inference=BootstrapInference(n_bootstrap_samples=100))  # or customized\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05) # Bootstrap confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e385e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sparse linear final stage'''\n",
    "from econml.dml import SparseLinearDML\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "est = SparseLinearDML(model_y=LassoCV(), model_t=LassoCV())\n",
    "est.fit(Y, T, X=X, W=W) # X -> high dimensional features\n",
    "treatment_effects = est.effect(X_test)\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05) # Confidence intervals via debiased lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Generic Machine Learning last stage'''\n",
    "from econml.dml import NonParamDML\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "est = NonParamDML(model_y=RandomForestRegressor(),\n",
    "                  model_t=RandomForestClassifier(),\n",
    "                  model_final=RandomForestRegressor(),\n",
    "                  discrete_treatment=True)\n",
    "est.fit(Y, T, X=X, W=W) \n",
    "treatment_effects = est.effect(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce810e2",
   "metadata": {},
   "source": [
    "**2. 双重稳健学习（Doubly Robust Learning）**\n",
    "\n",
    "双重稳健学习类似于双重机器学习，是一种在处理是分类变量时估计（异质性）处理效应的方法。所有潜在的混杂因素/控制变量（在收集的数据中同时直接影响处理决策和观察结果的因素）都被观察到，但因为数量太多（高维）而无法使用传统统计方法，或者它们对处理和结果的影响无法通过参数函数（非参数）令人满意地建模。这些问题都可以通过机器学习技术来解决。\n",
    "\n",
    "该方法首先将问题简化为两个预测任务：\n",
    "\n",
    "- 根据处理和控制变量预测结果，\n",
    "- 根据控制变量预测处理；\n",
    "\n",
    "与双重机器学习不同，第一个模型预测的结果是包括处理和控制变量在内的。\n",
    "然后，该方法将这两个预测模型结合在最后阶段的估计中，以创建异质性处理效应的模型。该方法允许使用任意的机器学习算法来完成这两个预测任务，同时保持与最终模型相关的许多有利的统计特性（例如，小的均方误差，渐近正态性，置信区间的构建）。如果这两个预测任务中的任何一个达到小的均方误差，那么最终模型的统计特性就成立（因此得名双重稳健）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Linear final stage'''\n",
    "from econml.dr import LinearDRLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "\n",
    "est = LinearDRLearner(model_propensity=GradientBoostingClassifier(),\n",
    "                      model_regression=GradientBoostingRegressor())\n",
    "est.fit(Y, T, X=X, W=W)\n",
    "treatment_effects = est.effect(X_test)\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd33a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Sparse linear final stage'''\n",
    "from econml.dr import SparseLinearDRLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "\n",
    "est = SparseLinearDRLearner(model_propensity=GradientBoostingClassifier(),\n",
    "                            model_regression=GradientBoostingRegressor())\n",
    "est.fit(Y, T, X=X, W=W)\n",
    "treatment_effects = est.effect(X_test)\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ab9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Nonparametric final stage'''\n",
    "from econml.dr import ForestDRLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "\n",
    "est = ForestDRLearner(model_propensity=GradientBoostingClassifier(),\n",
    "                      model_regression=GradientBoostingRegressor())\n",
    "est.fit(Y, T, X=X, W=W) \n",
    "treatment_effects = est.effect(X_test)\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcceb0",
   "metadata": {},
   "source": [
    "**3. 森林基础估计器(Forest-based Estimator)**\n",
    "\n",
    "森林基础估计器是一类使用决策树森林来估计处理效应异质性的因果推断方法。这些方法包括正交随机森林、因果森林和森林双重稳健估计器。它们都依赖于无混杂假设，即所有可能影响处理和结果的潜在变量都已被观察到。这些估计器的共同点在于它们都使用相似的矩方程来识别异质性处理效应，但它们在估计第一阶段的回归或分类模型时有所不同。正交随机森林估计器通过局部拟合来优化局部均方误差，而因果森林和森林双重稳健估计器则采用全局拟合。\n",
    "\n",
    "这些方法的优势在于它们能够适应数据的低维潜在结构，即使在特征数量众多的情况下也能表现良好。此外，这些方法能够提供有效的置信区间，这对于统计推断至关重要。EconML提供了三种这样的估计方法：\n",
    "\n",
    "- 正交随机森林估计器（DMLOrthoForest, DROrthoForest）\n",
    "- 森林双重机器学习估计器（即因果森林）（CausalForestDML）\n",
    "- 森林双重稳健估计器（ForestDRLearner）。\n",
    "\n",
    "这些估计器与DML和DRL部分类似，需要满足无混杂假设，即所有可能同时影响处理和结果的潜在变量都被观察到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61771790",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Orthogonal Random Forests '''\n",
    "from econml.orf import DMLOrthoForest, DROrthoForest\n",
    "from econml.sklearn_extensions.linear_model import WeightedLasso, WeightedLassoCV\n",
    "# Use defaults\n",
    "est = DMLOrthoForest()\n",
    "est = DROrthoForest()\n",
    "# Or specify hyperparameters\n",
    "est = DMLOrthoForest(n_trees=500, min_leaf_size=10,\n",
    "                     max_depth=10, subsample_ratio=0.7,\n",
    "                     lambda_reg=0.01,\n",
    "                     discrete_treatment=False,\n",
    "                     model_T=WeightedLasso(alpha=0.01), model_Y=WeightedLasso(alpha=0.01),\n",
    "                     model_T_final=WeightedLassoCV(cv=3), model_Y_final=WeightedLassoCV(cv=3))\n",
    "est.fit(Y, T, X=X, W=W)\n",
    "treatment_effects = est.effect(X_test)\n",
    "# Confidence intervals via Bootstrap-of-Little-Bags for forests\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Causal Forests'''\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.linear_model import LassoCV\n",
    "# Use defaults\n",
    "est = CausalForestDML()\n",
    "# Or specify hyperparameters\n",
    "est = CausalForestDML(criterion='het', n_estimators=500,       \n",
    "                      min_samples_leaf=10, \n",
    "                      max_depth=10, max_samples=0.5,\n",
    "                      discrete_treatment=False,\n",
    "                      model_t=LassoCV(), model_y=LassoCV())\n",
    "est.fit(Y, T, X=X, W=W)\n",
    "treatment_effects = est.effect(X_test)\n",
    "# Confidence intervals via Bootstrap-of-Little-Bags for forests\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce127b88",
   "metadata": {},
   "source": [
    "**4. 元学习器(Meta Learner)**\n",
    "\n",
    "元学习器是处理效应估计（CATE）的一类方法，专门针对分类处理变量。这些方法通过分别对控制组和处理组的响应面进行建模，或者对多个响应面进行建模。其在EconML中的实现方法主要有：\n",
    "- SLearner S-学习器\n",
    "通过一个模型来同时对控制组和处理组的响应进行建模，该模型将处理分配作为输入特征\n",
    "- TLearner T-学习器\n",
    "分别对控制组和处理组的响应进行建模。估计的CATE由两组模型的预测结果之差给出\n",
    "- XLearner\n",
    "分别对处理组和控制组的响应进行建模，以估计对已处理个体的条件平均处理效应（CATC）和对未处理个体的条件平均处理效应（CATT）。新个体的CATE估计由CATT和CATC的倾向加权平均给出\n",
    "- DomainAdaptationLearner\n",
    "使用领域自适应技术来估计结果模型，假设控制组和处理组的概率分布不同\n",
    "- NonParamDML\n",
    "提供非参数方法来估计CATE，适用于处理效应与特征之间关系未知的情况\n",
    "- DRLearner\n",
    "结合了回归调整和工具变量方法，提供稳健的CATE估计\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TLearner'''\n",
    "from econml.metalearners import TLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "est = TLearner(models=GradientBoostingRegressor())\n",
    "est.fit(Y, T, X=np.hstack([X, W]))\n",
    "treatment_effects = est.effect(np.hstack([X_test, W_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SLearner'''\n",
    "from econml.metalearners import SLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "est = SLearner(overall_model=GradientBoostingRegressor())\n",
    "est.fit(Y, T, X=np.hstack([X, W]))\n",
    "treatment_effects = est.effect(np.hstack([X_test, W_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09154398",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''XLearner'''\n",
    "from econml.metalearners import XLearner\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "est = XLearner(models=GradientBoostingRegressor(),\n",
    "              propensity_model=GradientBoostingClassifier(),\n",
    "              cate_models=GradientBoostingRegressor())\n",
    "est.fit(Y, T, X=np.hstack([X, W]))\n",
    "treatment_effects = est.effect(np.hstack([X_test, W_test]))\n",
    "\n",
    "# Fit with bootstrap confidence interval construction enabled\n",
    "est.fit(Y, T, X=np.hstack([X, W]), inference='bootstrap')\n",
    "treatment_effects = est.effect(np.hstack([X_test, W_test]))\n",
    "lb, ub = est.effect_interval(np.hstack([X_test, W_test]), alpha=0.05) # Bootstrap CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9c4e4",
   "metadata": {},
   "source": [
    "**5. Dynamic DML(动态双重机器学习)** ——Estimation Methods for Dynamic Treatment Regimes\n",
    "\n",
    "动态双重机器学习（Dynamic Double Machine Learning，简称Dynamic DML）是一种用于处理随时间顺序分配的处理效应估计的方法，**特别适用于存在动态混杂因素的情况**。这种方法可以应用于处理和结果数据随时间序列变化的情况，例如，在医疗、金融和营销等领域的动态决策过程。\n",
    "\n",
    "动态双重机器学习是一种在通过自适应动态策略随时间提供处理时估计（异质性）处理效应的方法。它适用于在收集的数据中，所有潜在的动态混杂因素/控制变量（同时直接影响自适应处理决策和观察到的结果的因素）都被观察到的情况，但这些因素要么太多（高维）以至于传统的统计方法不适用，要么它们对处理和结果的影响无法通过参数函数（非参数）令人满意地建模。这两个问题都可以通过DDML技术来解决。\n",
    "\n",
    "假设你有观察性（或来自A/B测试的实验）历史数据，在这些数据中随时间向每个单元提供了多个处理/干预/动作，并观察到了一些最终结果，并且所有可能影响选择的变量，并且同时可能直接影响结果（即控制变量或混杂因素）也被记录在数据集中。\n",
    "\n",
    "如果你的目标是了解处理对结果的影响如何依赖于被处理样本的一组可观察特征，那么可以使用这种方法。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31322a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dynamic Double Machine Learning'''\n",
    "from econml.panel.dml import DynamicDML\n",
    "# Use defaults\n",
    "est = DynamicDML()\n",
    "# Or specify hyperparameters\n",
    "est = DynamicDML(model_y=LassoCV(cv=3), \n",
    "                 model_t=LassoCV(cv=3), \n",
    "                 cv=3)\n",
    "est.fit(Y, T, X=X, W=None, groups=groups, inference=\"auto\")\n",
    "# Effects\n",
    "treatment_effects = est.effect(X_test)\n",
    "# Confidence intervals\n",
    "lb, ub = est.effect_interval(X_test, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a23d7",
   "metadata": {},
   "source": [
    "动态处理策略（Dynamic Treatment Regimes，DTRs）通常指的是随时间变化的治疗或干预措施，这些措施可能根据个体在先前时间点的反应或新信息进行调整。例如，在医疗领域，患者的治疗计划可能会根据他们对先前治疗的反应进行修改；在金融领域，投资策略可能会根据市场条件的变化进行调整。\n",
    "\n",
    "动态双重机器学习（Dynamic Double Machine Learning，Dynamic DML）是一类方法，专门用于估计这种随时间变化的处理策略的因果效应。这种方法考虑了处理分配的动态性质，并尝试估计在不同时间点采取不同行动的因果影响。\n",
    "\n",
    "应用场景主要包括：\n",
    "- 医疗决策：评估基于患者历史反应的个性化治疗方案的效果。\n",
    "- 市场营销：分析随时间变化的促销策略对消费者购买行为的影响。\n",
    "- 金融投资：评估根据市场条件动态调整的投资策略的回报。\n",
    "- 公共政策：评估随时间变化的政策干预措施的社会影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8755c65",
   "metadata": {},
   "source": [
    "**6. Estimation Methods with Instrumental Variable**\n",
    "- Deep Instrumental Variables\n",
    "\n",
    "深度工具变量（Deep Instrumental Variables，Deep IV）是一种利用神经网络来估计处理效应的方法，特别适用于存在潜在混杂变量时的情况。这种方法与传统的工具变量方法相比，可以处理更复杂的非线性关系，并允许使用灵活的模型结构。\n",
    "\n",
    "工具变量（IV）方法是一种在存在混杂的潜在变量的情况下估计因果效应的方法。所做的假设比DML所需的无混杂性假设要弱。代价是，当无混杂性成立时，IV估计器将比DML估计器的效率低。需要的是一个工具变量向量Z，假设它会影响处理T的分布，并且对结果Y的期望值没有直接的因果效应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d50c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Deep Instrumental Variables'''\n",
    "import keras\n",
    "from econml.iv.nnet import DeepIV\n",
    "\n",
    "treatment_model = keras.Sequential([keras.layers.Dense(128, activation='relu', input_shape=(2,)),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(64, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(32, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17)])\n",
    "response_model = keras.Sequential([keras.layers.Dense(128, activation='relu', input_shape=(2,)),\n",
    "                                  keras.layers.Dropout(0.17),\n",
    "                                  keras.layers.Dense(64, activation='relu'),\n",
    "                                  keras.layers.Dropout(0.17),\n",
    "                                  keras.layers.Dense(32, activation='relu'),\n",
    "                                  keras.layers.Dropout(0.17),\n",
    "                                  keras.layers.Dense(1)])\n",
    "est = DeepIV(n_components=10, # Number of gaussians in the mixture density networks)\n",
    "             m=lambda z, x: treatment_model(keras.layers.concatenate([z, x])), # Treatment model\n",
    "             h=lambda t, x: response_model(keras.layers.concatenate([t, x])), # Response model\n",
    "             n_samples=1 # Number of samples used to estimate the response\n",
    "             )\n",
    "est.fit(Y, T, X=X, Z=Z) # Z -> instrumental variables\n",
    "treatment_effects = est.effect(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53602893",
   "metadata": {},
   "source": [
    "- Orthogonal Instrumental Variables\n",
    "\n",
    "正交工具变量（Orthogonal Instrumental Variables，简称OrthoIV）是一类在存在未观察到的混杂因素时，利用有效工具变量来估计异质性处理效应的方法。这些方法通过将问题转化为最小化一个适当的损失函数来实现，该损失函数依赖于一组辅助模型。\n",
    "\n",
    "这些方法的优势在于它们可以与各种机器学习模型兼容，包括随机森林、梯度提升和神经网络等，从而能够灵活地处理复杂的数据结构和非线性关系。\n",
    "\n",
    "正交工具变量是一系列方法，可在存在未观察到的混杂因素的情况下，借助有效工具变量使用任意机器学习方法估计异质性处理效应。我们开发了一种统计学习方法来估计异质效应，将问题简化为最小化一个适当的损失函数，该函数依赖于一组辅助模型（每个模型对应一个单独的预测任务）。这种简化使得可以使用所有最新的机器学习模型（例如，随机森林、提升、神经网络）。我们通过展示损失满足Neyman正交性标准，证明了估计的效应模型对辅助模型的估计误差是稳健的。我们的方法可以用来估计在更简单的假设空间上的真实效应模型的投影。当这些空间是参数化的时，参数估计量是渐近正态的，这使得可以构建置信区间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Orthogonal Instrumental Variables'''\n",
    "\n",
    "from econml.iv.dr import LinearIntentToTreatDRIV\n",
    "est = LinearIntentToTreatDRIV()\n",
    "est.fit(y, T, Z=Z, X=X, W=X)\n",
    "est.effect(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
